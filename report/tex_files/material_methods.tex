\section{Materiales y métodos}

\subsection{Materiales}
A continuación, explicaremos los recursos y herramientas utilizados para los experimentos:

\vspace{3pt}

\textbf{Human Phenotype Ontology}\\ HPO es un vocabulario estandarizado de anomalías fenotípicas en enfermedades humanas que utiliza un fenotipado detallado para poder ser usado a nivel computacional \cite{HPO}.

\vspace{3pt}

\textbf{R}\\ R, en su esencia, es un lenguaje destinado a la exploración estadística y la creación de representaciones gráficas. Se configura como un entorno de programación compuesto por un conjunto de herramientas altamente adaptables, cuya funcionalidad puede ser expandida con facilidad a través de la integración de paquetes, bibliotecas o mediante la creación de funciones personalizadas. Además, se destaca por ser una plataforma de código abierto y gratuita, enmarcada en el proyecto GNU, compartiendo este enfoque con sistemas como Linux o aplicaciones como Mozilla Firefox. En nuestro caso hemos trabajado con la versión 4.3.1 de R \cite{Giorgi2022}.

\vspace{3pt}

\textbf{Python}\\
Python es un lenguaje de programación versátil de alto nivel ampliamente empleado en el desarrollo de diversas aplicaciones. A diferencia de lenguajes como Java o .NET, Python es interpretado, lo que significa que no requiere un proceso de compilación antes de ejecutar las aplicaciones. En lugar de eso, las aplicaciones escritas en Python se ejecutan directamente en la computadora utilizando un intérprete, eliminando la necesidad de traducción a lenguaje de máquina previamente. Este enfoque agiliza el desarrollo y ejecución de programas en Python. La versión utilizada de Python fue la 3.12.0 \cite{Mehare2023}.

\vspace{3pt}

\textbf{String}\\
String es una base de datos que alberga información sobre interacciones entre proteínas, tanto aquellas conocidas como las predichas. Estas interacciones abarcan desde asociaciones directas (físicas) hasta indirectas (funcionales). La base de datos recopila datos de diversas fuentes, que incluyen repositorios experimentales, métodos de predicción computacional y colecciones de textos públicos. Cada interacción está evaluada con una puntuación de condensación combinada que sintetiza las diversas evidencias disponibles\cite{Szklarczyk2021}.

\vspace{3pt}

\textbf{iGraph}\\
iGraph es una biblioteca rápida y de código abierto para el análisis de grafos o redes. El núcleo de esta librería está implementado en C y dispone de enlaces para su uso con lenguajes de alto nivel como R, Python y Mathematica \cite{Csardi2006}.

\vspace{3pt}

\textbf{Pandas}\\
Pandas es una biblioteca de programación en Python diseñada para facilitar el análisis y la manipulación de datos. Se centra en estructuras de datos como el "DataFrame", una tabla bidimensional, y ofrece funciones para cargar, limpiar y transformar datos de manera eficiente. Es ampliamente utilizado en ciencia de datos y análisis estadístico \cite{Snehkunj2022}.

\vspace{3pt}

\textbf{Algoritmos de clusterización}\\
Los algoritmos de clusterización son técnicas utilizadas en análisis de datos para dividir un conjunto de datos en grupos o "clústeres" basándose en similitudes entre los elementos. El objetivo es agrupar datos que sean más similares entre sí y más diferentes de otros grupos. Estos algoritmos ayudan a descubrir patrones y estructuras intrínsecas en los datos sin necesidad de etiquetas preexistentes. Los que se utilizaron para el trabajo fueron los siguientes:

•\textbf{Algoritmo de Givan-Newman}: es un método utilizado para detectar comunidades en redes complejas. Este algoritmo se basa en la idea de eliminar gradualmente los enlaces más importantes de una red para revelar su estructura de comunidad.

•\textbf{Algoritmo de optimización voraz}: también conocido como algoritmo ávido o greedy, es un enfoque de resolución de problemas que toma decisiones locales en cada etapa con la esperanza de encontrar una solución óptima global. En cada paso, el algoritmo selecciona la mejor opción disponible en ese momento, sin considerar las posibles consecuencias a largo plazo.

•\textbf{Algoritmo de propagación de etiquetas}: también conocido como "propagación de la afinidad," es un método de agrupamiento basado en la similitud entre los datos. A diferencia de otros algoritmos de agrupamiento que requieren la especificación del número de clústeres, la propagación de etiquetas es un algoritmo de agrupamiento sin la necesidad de definir previamente el número de clústeres.

•\textbf{Algoritmo de Louvain}: es un algoritmo de optimización utilizado para la detección de comunidades en redes o grafos. Su objetivo es encontrar una partición modular del grafo que maximice la modularidad. La modularidad es una medida que cuantifica la calidad de la partición de un grafo en comunidades, considerando la densidad de conexiones dentro de las comunidades y la rareza de conexiones entre ellas.

\vspace{3pt}

\textbf{Linkcomm}\\
Las comunidades de enlaces revelan la estructura anidada y superpuesta en las redes y descubren los nodos clave que forman conexiones con varias comunidades. Linkcomm proporciona un conjunto de herramientas para generar, visualizar y analizar comunidades de enlaces en redes de tamaño y tipo arbitrarios. El paquete linkcomm también incluye herramientas para generar, visualizar y analizar comunidades de Generadores de Clúster Superpuestos (OCG) \cite{Kalinka2011}.


\subsection{Métodos}
En primer lugar creamos una función que busca genes asociados a un fenotipo específico utilizando la API de \textbf{HPO}.
La función recibe el parámetro fenotipo, que es el código HPO para el fenotipo de interés.
Realizamos una solicitud GET a la API de HPO para obtener información sobre genes asociados al fenotipo.
Si la solicitud es exitosa (código de estado 200), extraemos y devolvemos los genes asociados al fenotipo. Si no, imprimimos un mensaje de error y devolvemos una lista vacía.


Utilizamos la función $buscar\_genes\_por\_fenotipo$ para obtener los genes asociados al fenotipo "Papilloma" (código HPO: HP:0012740).
Si encontramos genes asociados, imprimimos los nombres de los genes. Si no encontramos genes asociados, mostramos un mensaje indicando que no se encontraron genes.

Tras esto construimos una URL con los símbolos de los genes obtenidos anteriormente para realizar una solicitud a la API de StringDB, que proporciona información sobre interacciones de proteínas.
Realizamos una solicitud GET a la API de StringDB para obtener una red de interacciones de proteínas.
Guardamos la respuesta como una imagen llamada 'img.png'.

Imprimimos y filtramos los resultados del análisis de enriquecimiento por categorías ('Process' y 'KEGG').
Realizamos búsquedas específicas en los resultados de enfermedades y genes utilizando palabras clave y patrones de genes relevantes, respectivamente.
Guardamos los resultados de las búsquedas en archivos CSV .

Realizamos una solicitud GET a la API de StringDB para descargar la red de interacciones en formato TSV.
Si la descarga es exitosa, guardamos el archivo con el nombre proporcionado por la respuesta o como $'red_descargada.tsv'$ si no se obtiene un nombre de archivo.
Si hay un error en la descarga, imprimimos un mensaje de error.

Cargamos el archivo TSV descargado.
Seleccionamos columnas específicas ($'preferredName_A'$ y $'preferredName_B'$) y eliminamos duplicados.
Guardamos estas columnas en un nuevo archivo de texto llamado $'genes_igraph.txt'$.

\subsection{Propiedades de la red}

Nosotros usamos la biblioteca de \textbf{igraph} disponible en el lenguaje de programación de R para realizar el análisis y la visualización de la red. En primer lugar, importamos la librería y leímos el fichero que obtuvimos al generar la red con la API de STRINGDB y la guardamos en un grafo. A partir de este, estudiamos las \textbf{propiedades del grafo}, si todos los nodos estaban conectados con la función isconnected(), si era o no dirigido con la función is.directed(), el grado de centralidad que nos informaba del número de conexiones de cada gen con la función degree(), la centralidad de cercanía con la que obtuvimos la distancia promedio entre un nodo y todos los demás nodos mediante la aplicación de closeness(), y la conectividad que nos indicaba la fortaleza de la conexión del nodo aplicando $edge\_density()$. 

\vspace{3pt}
\subsection{Detección de comunidades}

En segundo lugar, llevamos a cabo la \textbf{identificación de comunidades} mediante distintos \textbf{algoritmos de clusterización}: método de Girvan-Newman, algoritmo de optimización voraz, propagación de etiquetas y el algoritmo de Louvain. 

\vspace{3pt}
\begin{enumerate}
\item El método de \textbf{Girvan Newman} (función $cluster_edge_betweenness()$, en el fichero $biologiasistemas_igraph.R$ en el repositorio GitHub del proyecto)detecta comunidades basándose en la centralidad de intermediación de los nodos, en otras palabras, va eliminando gradualmente las aristas más importantes para identificar las comunidades de la red \cite{Zahiri2023}.


\item El \textbf{algoritmo voraz} (función $cluster_fast_greedy()$, en el fichero $biologiasistemas_igraph.R$ en el repositorio GitHub del proyecto), busca formar grupos de datos de manera iterativa tomando en cada paso la elección más beneficiosa para fusionar o dividir clusters con el objetivo de maximizar un criterio local \cite{Curtis2003}.  


\item La \textbf{propagación de etiquetas} (función $cluster_label_prop()$, en el fichero $biologiasistemas_igraph.R$ en el repositorio GitHub del proyecto) es un enfoque basado en la difusión de información a través de la red que agrupa los nodos que están fuertemente conectados \cite{Garza2019}.

\item Por último el \textbf{algoritmo de Louvain} (función $cluster_louvain()$, en el fichero $biologiasistemas_igraph.R$ en el repositorio GitHub del proyecto)  busca organizar los nodos de una red en comunidades de manera que la modularidad global de la red sea máxima, o en otras palabras, cómo de bien se dividen los nodos de una red en grupos o comunidades distintas \cite{Zhang2021}.

\end{enumerate}

\vspace{3pt}

Para estudiar mejor a qué comunidad pertenece cada nodo, visualizamos el resultado de la aplicación del algoritmo de Louvain mediante la aplicación de \textbf{link communities} (función getLinkCommunities(), en el fichero $biologiasistemas_igraph.R$ en el repositorio GitHub del proyecto) que nos permitía identificar si alguno de los nodos se incluían en varias comunidades. 

\vspace{3pt}
\subsection{Interacción de genes de interés}

En tercer lugar, estudiamos la interacción de nuestros \textbf{genes de interés} especificados anteriormente: \textit{TP53}, \textit{HRAS}, \textit{AKT1}, \textit{SDHB}, \textit{SDHD}. Para ellos creamos una función (función $encontrar\_vecinos\_interesantes()$, en el fichero $biologiasistemas\_igraph.R$ en el repositorio GitHub del proyecto) que nos devolvía una tabla con los vecinos de cada uno de estos genes para saber si entre ellos estaban relacionados.

\vspace{3pt}

\subsection{Enriquecimiento funcional de la comunidad de interés.}

Tras estudiar la detección de comunidades optamos por realizar un enriquecimiento funcional de la comunidad en la que se encuentran nuestros genes de interés. Para ello, se busca la comunidad en la que se encuentran estos genes, se identifica esta y se guardan los genes que la conforman en el entorno de R. Esto lo hemos hecho con el comando \textit{ nodos\_genes\_interes \textless\ - V(net) \$name \%in\% genes\_interes} donde \textit{net} es nuestro grafo principal y $genes\_interes$ es un vector donde se encuentran definidos los genes de interés del estudio. Este comando encuentra los índices de los nodos que representan los genes de interés nuestro de nuestro grafo. Seguimos, obteniendo el índice de la comunidad que contiene estos genes de interés con el comando \textit{ cluster\_containing\_genes \textless\ - mermbership(cfg)[nodos\_genes\_interes]} donde $cfg$ es la variable donde se encuentran las diferentes comunidades que hemos identificado en nuestro grafo principal. Tras esto, con el comando \textit{genes\_cluster \textless\ - V(net)\$name[membership(cfg)==cluster\_containing\_genes]} guardamos todos los genes que conforman esta comunidad en una variable. Esta variable la guardamos en un fichero de texto con la función $write.table()$.

\vspace{3pt}

Una vez que tenemos el fichero de texto con los genes que conforman la comunidad de interés procedemos a realizar un enriquecimiento funcional. Para ello, en un nuevo script de Python que hemos llamado \textit{enriquecimiento\_cluster.py}. Comenzamos importando las librería necesarias y construyendo la URL para realizar una solicitud a la API de STRINGDB. Definimos la categoría funcional de interés, en nuestro caso HPO (para relacionar los genes con fenotipos patológicos), definimos la especie de nuestros genes, en este caso 9606 (referente a Homo Sapiens) y el archivo de genes donde se enucnetran nuestra comunidad de interés. Seguidamente recogemos los parámetros para el análisis funcional ya definidos en una solicitud a la API de StringDB. Creamos un dataframe con las columnas $Term, Preferred Name, Category, Description$ que muestran el término HPO, el nombre de los genes, la categoría funcional (en este caso, HPO) y una descripción del fenotipo patológico asociado.
Este dataset se guarda en un archivo csv con la función \textit{.to\_csv()}.

\vspace{3pt}

\subsection{Consulta de la relación entre genes asociados y fenotipos patológicos.}

Por último, hemos consultado manualmente el archivo csv creado con el dataframe anteriormente descrito y hemos identificado relaciones de genes asociados con fenotipos patológicos (estas consultas han sido filtradas por palabras clave como son: papiloma, genitales, renal, carcinoma, ovario y derivados, útero y derivados).


